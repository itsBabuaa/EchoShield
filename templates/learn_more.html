{% extends "base.html" %}

{% block title %}Learn More - EchoShield{% endblock %}

{% block content %}
<div class="learn-container">
    <h1 class="page-title">Understanding Deepfake Technology</h1>
    
    <!-- Introduction -->
    <section class="learn-section">
        <h2>What Are Deepfakes?</h2>
        <p>Deepfakes are synthetic media created using artificial intelligence and deep learning techniques. The term combines "deep learning" and "fake" to describe content that has been manipulated or entirely generated by AI to appear authentic.</p>
        <p>While deepfakes can be used for entertainment and creative purposes, they pose significant risks when used maliciously to deceive, defraud, or manipulate public opinion.</p>
    </section>

    <!-- How It Works -->
    <section class="learn-section">
        <h2>How Deepfake Audio Works</h2>
        <div class="tech-grid">
            <div class="tech-card">
                <h3>1. Data Collection</h3>
                <p>AI systems analyze hours of real audio recordings to learn voice patterns, intonation, accent, and speech characteristics of the target person.</p>
            </div>
            <div class="tech-card">
                <h3>2. Model Training</h3>
                <p>Neural networks, particularly Generative Adversarial Networks (GANs) and autoencoders, are trained to replicate the voice patterns with high accuracy.</p>
            </div>
            <div class="tech-card">
                <h3>3. Voice Synthesis</h3>
                <p>The trained model can generate new speech in the target's voice, saying words or sentences they never actually spoke.</p>
            </div>
            <div class="tech-card">
                <h3>4. Refinement</h3>
                <p>Advanced techniques add natural imperfections, breathing sounds, and emotional nuances to make the fake audio more convincing.</p>
            </div>
        </div>
    </section>

    <!-- Real-World Cases -->
    <section class="learn-section">
        <h2>Real-World Cases</h2>
        <div class="case-study">
            <h3>üè¢ Corporate Fraud (2019)</h3>
            <p>A UK-based energy company CEO received a call from who he thought was his boss, the CEO of the parent company. The voice was a deepfake, and the fraudsters successfully stole $243,000.</p>
        </div>
        <div class="case-study">
            <h3>üó≥Ô∏è Political Manipulation (2020)</h3>
            <p>Deepfake audio of political figures has been used to spread misinformation during elections, creating false statements that went viral before fact-checkers could respond.</p>
        </div>
        <div class="case-study">
            <h3>üí∞ Banking Fraud (2021)</h3>
            <p>Criminals used deepfake voice technology to bypass voice authentication systems at multiple banks, gaining unauthorized access to customer accounts.</p>
        </div>
    </section>

    <!-- Types of Harm -->
    <section class="learn-section">
        <h2>Types of Harm</h2>
        <div class="harm-list">
            <div class="harm-item">
                <div class="harm-icon-large">üí∏</div>
                <h3>Financial Fraud</h3>
                <p><strong>Impact:</strong> Billions in losses annually</p>
                <ul>
                    <li>CEO fraud and business email compromise</li>
                    <li>Voice authentication bypass</li>
                    <li>Investment scams using celebrity voices</li>
                    <li>Insurance fraud with fabricated evidence</li>
                </ul>
            </div>
            
            <div class="harm-item">
                <div class="harm-icon-large">üé≠</div>
                <h3>Reputation Damage</h3>
                <p><strong>Impact:</strong> Irreversible personal and professional harm</p>
                <ul>
                    <li>False statements attributed to public figures</li>
                    <li>Fake confessions or admissions</li>
                    <li>Manufactured scandals</li>
                    <li>Career-ending fabrications</li>
                </ul>
            </div>
            
            <div class="harm-item">
                <div class="harm-icon-large">üåê</div>
                <h3>Social Manipulation</h3>
                <p><strong>Impact:</strong> Erosion of trust in media and institutions</p>
                <ul>
                    <li>Election interference</li>
                    <li>Propaganda and disinformation campaigns</li>
                    <li>Inciting violence or panic</li>
                    <li>Undermining democratic processes</li>
                </ul>
            </div>
            
            <div class="harm-item">
                <div class="harm-icon-large">üîí</div>
                <h3>Security Threats</h3>
                <p><strong>Impact:</strong> National security and corporate espionage</p>
                <ul>
                    <li>Impersonation of military or government officials</li>
                    <li>Corporate espionage and trade secret theft</li>
                    <li>Social engineering attacks</li>
                    <li>Bypassing biometric security systems</li>
                </ul>
            </div>
        </div>
    </section>

    <!-- Detection Methods -->
    <section class="learn-section">
        <h2>How We Detect Deepfakes</h2>
        <p>Our system uses advanced machine learning techniques to identify synthetic audio:</p>
        <div class="detection-methods">
            <div class="method-card">
                <h3>üéµ MFCC Analysis</h3>
                <p>Mel-Frequency Cepstral Coefficients capture the unique spectral characteristics of audio that differ between real and synthetic speech.</p>
            </div>
            <div class="method-card">
                <h3>üß† BiLSTM Neural Network</h3>
                <p>Bidirectional Long Short-Term Memory networks analyze temporal patterns in audio sequences to detect AI-generated artifacts.</p>
            </div>
            <div class="method-card">
                <h3>üìä Pattern Recognition</h3>
                <p>Our model identifies subtle inconsistencies in breathing, intonation, and micro-pauses that are difficult for AI to replicate perfectly.</p>
            </div>
            <div class="method-card">
                <h3>‚úÖ Continuous Learning</h3>
                <p>The system is trained on thousands of real and fake audio samples, constantly improving its detection capabilities.</p>
            </div>
        </div>
    </section>

    <!-- Protection Tips -->
    <section class="learn-section">
        <h2>How to Protect Yourself</h2>
        <div class="tips-grid">
            <div class="tip-card">
                <div class="tip-number">1</div>
                <h3>Verify Unusual Requests</h3>
                <p>Always verify unexpected calls requesting money transfers or sensitive information through a secondary channel.</p>
            </div>
            <div class="tip-card">
                <div class="tip-number">2</div>
                <h3>Use Code Words</h3>
                <p>Establish secret code words with family and colleagues for emergency situations or sensitive requests.</p>
            </div>
            <div class="tip-card">
                <div class="tip-number">3</div>
                <h3>Enable Multi-Factor Authentication</h3>
                <p>Don't rely solely on voice authentication. Use multiple verification methods for important accounts.</p>
            </div>
            <div class="tip-card">
                <div class="tip-number">4</div>
                <h3>Stay Informed</h3>
                <p>Keep up with deepfake technology developments and learn to recognize common red flags.</p>
            </div>
            <div class="tip-card">
                <div class="tip-number">5</div>
                <h3>Use Detection Tools</h3>
                <p>Verify suspicious audio using detection tools like ours before taking action on unusual requests.</p>
            </div>
            <div class="tip-card">
                <div class="tip-number">6</div>
                <h3>Report Suspicious Content</h3>
                <p>Report potential deepfakes to relevant authorities and platforms to help combat their spread.</p>
            </div>
        </div>
    </section>

    <!-- CTA -->
    <section class="cta-section">
        <h2>Ready to Detect Deepfakes?</h2>
        <p>Use our AI-powered tool to verify audio authenticity</p>
        <a href="/detect" class="btn-primary btn-large">Start Detection Now</a>
    </section>
</div>
{% endblock %}
